# name: Databricks CD Pipeline

# on:
#   workflow_run:
#     workflows: ["Databricks CI Pipeline"]  # This is the name of your CI pipeline.
#     types:
#       - completed

# jobs:
#   deploy:
#     runs-on: ubuntu-22.04

#     env:
#       DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
#       DATABRICKS_BUNDLE_PATH: ${{ github.workspace }}/databricks_build.zip  # The path to the zip artifact
      

#     steps:
#       - name: Print Run ID
#         run: |
#           echo "run id: ${{ github.event.workflow_run.id }}"

#       - name: Download Databricks Build Artifact
#         uses: actions/download-artifact@v4
#         with:
#           name: DatabricksBuild
#           github-token: ${{ secrets.GH_PAT }}
#           run-id: ${{ github.event.workflow_run.id }}
#           path: ${{ github.workspace }}
      
#       - name: Unzip the Artifact
#         run: |
#           echo "Unzipping the artifact... "
#           unzip ${{ github.workspace }}/databricks_build.zip -d ${{ github.workspace }}/databricks_build/

#       - name: Install Databricks CLI
#         run: |
#           curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh

#       - name: List cwd and files
#         run: |
#             echo "Current working directory:"
#             pwd
#             echo "Files in the current directory:"
#             ls -la
#             echo "Changing working directory"
#             cd databricks_build
#             echo "New current working directory:"
#             pwd
#             echo "Files in the current directory:"
#             ls -la

#       - name: Deploy Databricks Asset Bundle
#         run: |
#           cd databricks_build
#           echo "Deploying DAB bundle..."
#           databricks bundle deploy -t prod
#           # echo "Running the DAB bundle..."
#           # databricks bundle run -t prod source_A_etl
#         env:
#           DATABRICKS_CLIENT_ID: ${{ secrets.SP_ID}}
#           DATABRICKS_CLIENT_SECRET: ${{secrets.SP_TOKEN}}

#       - name: Confirm Deployment
#         run: |
#           echo "DAB bundle deployed and job executed successfully ! "
#           databricks workspace mkdirs /Workspace/Production/wheels
#           databricks workspace move /Workspace/Production/source-A-bundle/artifacts/.internal/my_wheel-0.1.5-py3-none-any.whl /Workspace/Production/wheels/finished.whl


name: Databricks CD Pipeline

on:
  workflow_run:
    workflows: ["Databricks CI Pipeline"]
    types:
      - completed

jobs:
  deploy:
    runs-on: ubuntu-22.04

    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_BUNDLE_PATH: ${{ github.workspace }}/databricks_build.zip
      DATABRICKS_CLIENT_ID: ${{ secrets.SP_ID }}
      DATABRICKS_CLIENT_SECRET: ${{ secrets.SP_TOKEN }}

    steps:
      - name: Print Run ID
        run: |
          echo "run id: ${{ github.event.workflow_run.id }}"

      - name: Download Databricks Build Artifact
        uses: actions/download-artifact@v4
        with:
          name: DatabricksBuild
          github-token: ${{ secrets.GH_PAT }}
          run-id: ${{ github.event.workflow_run.id }}
          path: ${{ github.workspace }}

      - name: Unzip the Artifact
        run: |
          echo "Unzipping the artifact..."
          unzip ${{ github.workspace }}/databricks_build.zip -d ${{ github.workspace }}/databricks_build/

      - name: Install Databricks CLI
        run: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh

      - name: Set Databricks Authentication  # ðŸ”¥ Fix: Set auth variables before using CLI
        run: |
          echo "Configuring Databricks authentication..."
          export DATABRICKS_ACCESS_TOKEN=$(databricks oauth token --client-id $DATABRICKS_CLIENT_ID --client-secret $DATABRICKS_CLIENT_SECRET --host $DATABRICKS_HOST)
          echo "Databricks authentication configured successfully."

      - name: List cwd and files
        run: |
          echo "Current working directory:"
          pwd
          echo "Files in the current directory:"
          ls -la
          echo "Changing working directory"
          cd databricks_build
          echo "New current working directory:"
          pwd
          echo "Files in the current directory:"
          ls -la

      - name: Deploy Databricks Asset Bundle
        run: |
          cd databricks_build
          echo "Deploying DAB bundle..."
          databricks bundle deploy -t prod

      - name: Export the File from Databricks Workspace to Local Directory
        run: |
            echo "Exporting the wheel file from Databricks workspace..."
            databricks workspace export /Workspace/Production/source-A-bundle/artifacts/.internal/my_wheel-0.1.5-py3-none-any.whl 
  
      - name: Import the File to Target Databricks Workspace Folder
        run: |
            echo "Importing the wheel file to the target workspace folder..."
            databricks workspace import ./my_wheel-0.1.5-py3-none-any.whl /Workspace/Production/wheels/finished.whl --overwrite
  
      - name: Confirm Deployment
        run: |
            echo "Deployment successful!"
            databricks workspace ls /Workspace/Production/wheels/