# This is a Databricks asset bundle definition for asset_bundles_template_test_1.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.
bundle:
  name: source-A-bundle

include:
  - resources/*.yml

sync:
  exclude:
    - .vscode
    - .gitignore
    - fixtures

variables:
  prod_path:
    description: 'Folder in which bundle will be deployed when approved for production (-t prod)'
    default: /Production/${bundle.name}/

  cluster_id_testing_cluster:
    description: id of cluster used for (nutter) testing
    default: 0316-094940-oenlls44

targets:
  # The 'dev' target, for development purposes. This target is the default.
  dev:
    # We use 'mode: development' to indicate this is a personal development copy:
    # - Deployed resources get prefixed with '[dev my_user_name]'
    # - Any job schedules and triggers are paused by default
    # - The 'development' mode is used for Delta Live Tables pipelines
    mode: development
    default: true
    workspace:
      host: https://adb-1909067673949101.1.azuredatabricks.net/

  #############################################################################################################################
  # The 'prod' target, used for production deployment.
  prod:
    # We use 'mode: production' to indicate this is a production deployment.
    # Doing so enables strict verification of the settings below.
    mode: production
    workspace:
      host: https://adb-1909067673949101.1.azuredatabricks.net/
      # We only have a single deployment copy for production, 
      # so we use a shared path.
      root_path: ${var.prod_path}
    run_as:
      # This runs as user.name@domain.com in production. 
      # We could also use a service principal here
      # using service_principal_name 
      # (see https://docs.databricks.com/dev-tools/bundles/permissions.html).
      user_name: bbluestone@outlook.com

    sync:
      include:
        - src/*

    # resources:
    #   jobs:
    #     source_A_etl:
    #       job_clusters:
    #         - job_cluster_key: job_cluster_category_1
    #           new_cluster:
    #             spark_version: 13.3.x-scala2.12
    #             node_type_id: Standard_D5_v2
    #             autoscale:
    #               min_workers: 1
    #               max_workers: 1
    #       tasks:
    #         - task_key: upload_to_bronze
    #           job_cluster_key: job_cluster_category_1
    #           notebook_task:
    #             notebook_path: ./src/source_A_1_raw_to_bronze_notebook.py

    #         - task_key: bronze_to_silver
    #           job_cluster_key: job_cluster_category_1
    #           notebook_task:
    #             notebook_path: ./src/source_A_2_bronze_to_silver_notebook.py

    #         - task_key: silver_to_gold
    #           job_cluster_key: job_cluster_category_1
    #           notebook_task:
    #             notebook_path: ./src/source_A_3_silver_to_gold_notebook.py